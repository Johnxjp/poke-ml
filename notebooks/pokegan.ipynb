{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PokeGAN\n",
    "\n",
    "Simple GAN trained on all the pokemon sprite images. No transfer learning is used and the only input to the generator is the random vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_root_dir = \"../data/images/\"\n",
    "image_data, filenames = load_raw_data(image_root_dir, image_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = [\n",
    "    image_data[filenames.index(\"001MS.png\")],\n",
    "    image_data[filenames.index(\"002MS.png\")],\n",
    "    image_data[filenames.index(\"003XYMS.png\")]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_w, image_h = image_data[0].size\n",
    "image_h, image_w, image_data[0].mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.choice(len(image_data), size=len(image_data), replace=False)\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "for i, img_index in enumerate(sample):\n",
    "    ax = fig.add_subplot(3, 6, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(image_data[img_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets & DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_color = True\n",
    "n_channels = 3 if use_color else 1\n",
    "if use_color:\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "else:\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Grayscale(),\n",
    "        transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = ImageDataset(image_data, data_transforms)\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sample = next(iter(training_dataloader))\n",
    "dataset_sample = batch_sample[0]\n",
    "dataset_sample = dataset_sample.permute(1, 2, 0)\n",
    "if not use_color:\n",
    "    dataset_sample = dataset_sample.squeeze()\n",
    "plt.imshow(dataset_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = DCDiscriminator(image_h, image_w, kernel_size=4, padding=1, is_rgb=use_color)\n",
    "D.init_weights()\n",
    "D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_size = 100\n",
    "G = DCGenerator(noise_size, image_h, image_w, kernel_size=4, padding=1, is_rgb=use_color)\n",
    "G.init_weights()\n",
    "G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate for optimizers\n",
    "lr_d = 0.0004\n",
    "lr_g = 0.001\n",
    "\n",
    "# Create optimizers for the discriminator and generator\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=lr_d, betas=(0.5, 0.999))\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=lr_g, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training hyperparams\n",
    "num_epochs = 500\n",
    "\n",
    "# keep track of loss and generated, \"fake\" samples\n",
    "samples = []\n",
    "losses = []\n",
    "\n",
    "print_every = 400\n",
    "\n",
    "# Get some fixed data for sampling. These are images that are held\n",
    "# constant throughout training, and allow us to inspect the model's performance\n",
    "sample_size=16\n",
    "fixed_z = generate_random((sample_size, noise_size))\n",
    "fixed_z = torch.from_numpy(fixed_z).float()\n",
    "\n",
    "# train the network\n",
    "D.train()\n",
    "G.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_i, real_images in enumerate(training_dataloader):                \n",
    "        batch_size = real_images.size(0)\n",
    "        real_images = scale(real_images)\n",
    "        \n",
    "        # ============================================\n",
    "        #            TRAIN THE DISCRIMINATOR\n",
    "        # ============================================\n",
    "                \n",
    "        # 1. Train with real images\n",
    "        d_optimizer.zero_grad()\n",
    "        \n",
    "        # Compute the discriminator losses on real images\n",
    "        # use smoothed labels\n",
    "        batch_out_real = D(real_images)\n",
    "        d_real_loss = real_loss(batch_out_real, smooth=True)\n",
    "        \n",
    "        # 2. Train with fake images\n",
    "        # Generate fake images\n",
    "        z = generate_random((batch_size, noise_size))\n",
    "        z = torch.from_numpy(z).float()\n",
    "        fake_images = G(z)\n",
    "        \n",
    "        # Compute the discriminator losses on fake images        \n",
    "        \n",
    "        # add up real and fake losses and perform backprop\n",
    "        batch_out_fake = D(fake_images)\n",
    "        d_fake_loss = fake_loss(batch_out_fake)\n",
    "    \n",
    "        d_loss = d_fake_loss + d_real_loss\n",
    "        d_loss.backward(retain_graph=True)\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # =========================================\n",
    "        #            TRAIN THE GENERATOR\n",
    "        # =========================================\n",
    "        \n",
    "        \n",
    "        # 1. Train with fake images and flipped labels\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss = real_loss(batch_out_fake)\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        # Print some loss stats\n",
    "        if batch_i % print_every == 0:\n",
    "            # print discriminator and generator loss\n",
    "            print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
    "                    epoch+1, num_epochs, d_loss.item(), g_loss.item()))\n",
    "\n",
    "    \n",
    "    ## AFTER EACH EPOCH##\n",
    "    # append discriminator loss and generator loss\n",
    "    losses.append((d_loss.item(), g_loss.item()))\n",
    "    \n",
    "    # generate and save sample, fake images\n",
    "    G.eval() # eval mode for generating samples\n",
    "    samples_z = G(fixed_z)\n",
    "    samples.append(samples_z)\n",
    "    G.train() # back to train mode\n",
    "\n",
    "\n",
    "# Save training generator samples\n",
    "with open('train_samples.pkl', 'wb') as f:\n",
    "    pkl.dump(samples, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loss\n",
    "\n",
    "Here we'll plot the training losses for the generator and discriminator, recorded after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "losses = np.array(losses)\n",
    "plt.plot(losses.T[0], label='Discriminator')\n",
    "plt.plot(losses.T[1], label='Generator')\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_sample(samples, img_size, is_rgb=True):\n",
    "    samples = (samples + 1) / 2  # Reverse scaling\n",
    "    samples = samples.permute(0, 2, 3, 1)\n",
    "    samples.detach()\n",
    "    return samples.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly generated, new latent vectors\n",
    "sample_size=16\n",
    "rand_z = generate_random((sample_size, noise_size))\n",
    "rand_z = torch.from_numpy(rand_z).float()\n",
    "\n",
    "G.eval() # eval mode\n",
    "# generated samples\n",
    "with torch.no_grad():\n",
    "    rand_images = G(rand_z)\n",
    "    \n",
    "reshaped_images = reshape_sample(rand_images, image_w, is_rgb=use_color).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "for i, s in enumerate(reshaped_images):\n",
    "    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(s, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Training Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples = pkl.load(open(\"train_samples.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(training_samples), 25):\n",
    "    reshaped_images = reshape_sample(training_samples[i].detach(), image_w, is_rgb=use_color)\n",
    "    fig = plt.figure(figsize=(7, 7))\n",
    "    for i, s in enumerate(reshaped_images):\n",
    "        ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "        ax.imshow(s, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
